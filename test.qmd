---
title: "Assigned Reading: Breiman (2001) - Statistical Modeling: The Two Cultures"
format: html
---

# Breiman (2001) Notes & Review

## Section 5–5.1: The Use of Data Models

<details>

<summary>Click to expand notes: Section 5–5.1</summary>

-   Statisticians often focus too much on models.
-   Nature is complex; it is unreasonable to assume a model fully captures it.
-   Models are mathematically attractive: allow hypothesis tests, goodness-of-fit, and confidence intervals.
-   Using R² or coefficients without checking if data could be produced by the model can lead to wrong conclusions.

</details>

### Review

-   Breiman critiques over-reliance on parametric models.
-   Mathematical convenience does not guarantee truth.
-   Important to consider whether the model can represent real data.

------------------------------------------------------------------------

## Section 5.2: Problems in Current Data Modeling

<details>

<summary>Click to expand notes: Section 5.2</summary>

-   Residual plots and goodness-of-fit are unreliable in high dimensions.
-   Simulations show linearity is not rejected until deviations are extreme.
-   High-dimensional interactions can produce “passable” residual plots for multiple models.
-   Acceptable diagnostics do **not** imply a good fit.
-   Predictive performance is a more trustworthy measure than model fit.

</details>

### Review

-   Classical diagnostics can mask model misspecification.
-   Predictive evaluation on new data is critical.

------------------------------------------------------------------------

## Section 5.3: Multiplicity of Data Models

<details>

<summary>Click to expand notes: Section 5.3</summary>

-   Many different models can fit the same data equally well.
-   Each model can imply very different relationships between inputs and outputs.
-   Inference depends heavily on model choice; coefficients may be unstable.
-   Data alone cannot reveal a unique “true” model.

</details>

### Review

-   Breiman challenges the assumption that fitting a model uncovers the true structure.
-   Focus should shift from identifying the “true model” to evaluating predictions.

------------------------------------------------------------------------

## Section 5.4: Predictive Accuracy

<details>

<summary>Click to expand notes: Section 5.4</summary>

-   Predictive accuracy measures how well a model performs on **new data**.
-   Nature’s box analogy: feed X to nature’s box → Y, feed X to model → Y_hat, compare.
-   Cross-validation or test sets estimate predictive accuracy and correct overfitting bias.
-   Predictive evaluation is more meaningful than residuals, R², or significance tests.

</details>

### Review

-   Predictive performance is the main criterion for model evaluation.
-   Focus on generalization, not internal fit.

------------------------------------------------------------------------

## Section 6: Limitations of Data Models

<details>

<summary>Click to expand notes: Section 6</summary>

-   Models are almost always misspecified; assumptions are rarely true.
-   Diagnostics fail in high-dimensional, complex systems.
-   Multiplicity of models leads to instability in inference.
-   Overfitting inflates apparent accuracy; cross-validation/test sets help reduce bias.
-   Complex interactions in real-world data cannot be fully captured.

</details>

### Review

-   Traditional data modeling is fragile in complex real systems.
-   Predictive validation is more reliable than assumption-based inference.

------------------------------------------------------------------------

## Section 7.2: Theory in Algorithmic Modeling

<details>

<summary>Click to expand notes: Section 7.2</summary>

-   Algorithmic modeling rarely uses data models.
-   Nature is treated as a black box: complex, mysterious, partly unknowable.
-   Goal: find an algorithm so that for future X, f(X) accurately predicts Y.
-   Focus is on **properties of algorithms**: predictive strength, iterative convergence, robustness.
-   Only assumption: data are drawn from an unknown multivariate distribution.
-   Examples: neural networks, decision trees, boosting.

</details>

### Review

-   Algorithmic modeling emphasizes prediction over interpretability.
-   Algorithms are evaluated by out-of-sample performance, not by fitting assumptions.
-   Suitable for complex, high-dimensional problems where classical models fail.
